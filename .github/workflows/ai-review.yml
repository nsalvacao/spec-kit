# =============================================================================
# ü§ñ AI Review ‚Äî inline, no cross-repo reusable dependency
# Uses GitHub Models free tier ‚Äî ZERO premium requests consumed
#
# Configurable via env block at the top of each job:
#   REVIEW_MODEL           ‚Äî primary model for code review         (#77)
#   REVIEW_FALLBACK_MODEL  ‚Äî fallback model if primary 429s        (#77)
#   REVIEW_FALLBACK_MODEL_2‚Äî 2nd fallback (higher rate limits)     (#77)
#   SUMMARY_MODEL          ‚Äî primary model for PR summary          (#77)
#   SUMMARY_FALLBACK_MODEL ‚Äî fallback model if primary 429s        (#77)
#   SUMMARY_FALLBACK_MODEL_2‚Äî 2nd fallback (higher rate limits)    (#77)
#   MAX_REVIEW_CHARS       ‚Äî max diff chars for review             (#76)
#   MAX_SUMMARY_CHARS      ‚Äî max diff chars for summary            (#76)
#   MAX_RETRY              ‚Äî retry attempts per model              (#77)
#   Review timeline logs are append-only per run (UTC timestamps)
#   and exported to the workflow summary for easier debugging.
# =============================================================================
name: AI Review

on:
  pull_request:
    types: [opened, synchronize, reopened]
    paths:
      - "src/**"
      - "tests/**"
      - "scripts/**"
      - "templates/**"
      - ".github/workflows/**"
      - "pyproject.toml"
      - "uv.lock"

permissions:
  contents: read
  pull-requests: write

jobs:
  code-review:
    name: AI Code Review
    runs-on: ubuntu-latest
    # Skip review for PRs labelled 'skip-ai-review' (#76)
    if: ${{ !contains(github.event.pull_request.labels.*.name, 'skip-ai-review') }}
    env:
      REVIEW_LONG_CONTEXT_MODEL: "google/gemini-2.0-flash" # prefer long-context model first (free tier; check runtime headers for limits)
      REVIEW_MODEL: "openai/gpt-4.1"
      REVIEW_FALLBACK_MODEL: "openai/gpt-4o"
      MAX_REVIEW_CHARS: "50000"
      MAX_REVIEW_TOKENS: "2000"
      CHUNK_SIZE_CHARS: "18000"
      CHUNK_OVERLAP_CHARS: "1200"
      MAX_RETRY: "5"
      MAX_RETRY_SLEEP: "60"
    steps:
      - name: Checkout
        uses: actions/checkout@v6
        with:
          fetch-depth: 0

      - name: Get PR diff
        id: diff
        run: |
          set -euo pipefail
          git diff ${{ github.event.pull_request.base.sha }}...${{ github.event.pull_request.head.sha }} > diff_full.txt
          DIFF_SIZE=$(wc -c < diff_full.txt)
          echo "full_size=$DIFF_SIZE" >> "$GITHUB_OUTPUT"

          if [ "$DIFF_SIZE" -gt "$MAX_REVIEW_CHARS" ]; then
            echo "chunk_required=true" >> "$GITHUB_OUTPUT"
          else
            echo "chunk_required=false" >> "$GITHUB_OUTPUT"
          fi

          # no truncation; chunking later if required
          echo "truncated=false" >> "$GITHUB_OUTPUT"
          echo "truncated_at=0" >> "$GITHUB_OUTPUT"

          if [ ! -s diff_full.txt ]; then
            echo "skip=true" >> "$GITHUB_OUTPUT"
          else
            echo "skip=false" >> "$GITHUB_OUTPUT"
          fi

      - name: AI Review via GitHub Models (with retry)
        if: steps.diff.outputs.skip != 'true'
        id: review
        env:
          GH_MODELS_TOKEN: ${{ secrets.MODELS_PAT }}
        run: |
          set -euo pipefail
          # Mask token to prevent accidental log exposure
          echo "::add-mask::$GH_MODELS_TOKEN"

          SYSTEM_PROMPT="You are a senior code reviewer. Review this diff for: 1) Security vulnerabilities 2) Bugs 3) Best practice violations. Use markdown with severity: üî¥ Critical, üü° Warning, üîµ Info. Be concise but thorough."
          CHUNK_REQUIRED=${{ steps.diff.outputs.chunk_required == 'true' && '1' || '0' }}
          TIMELINE_FILE="review_timeline.md"
          : > "$TIMELINE_FILE"

          timeline() {
            local MESSAGE="$1"
            printf '%s | %s\n' "$(date -u '+%Y-%m-%dT%H:%M:%SZ')" "$MESSAGE" | tee -a "$TIMELINE_FILE" >&2
          }

          timeline "AI review started full_diff_chars=${{ steps.diff.outputs.full_size }} chunk_required=$CHUNK_REQUIRED"

          call_model() {
            local MODEL="$1" CONTENT="$2" PURPOSE="$3" CHUNK_ID="$4"
            local HEADERS_FILE="/tmp/headers-$CHUNK_ID.txt"
            local INPUT_CHARS=${#CONTENT}
            timeline "request purpose=$PURPOSE chunk=$CHUNK_ID model=$MODEL input_chars=$INPUT_CHARS"

            RESPONSE=$(curl -s -D "$HEADERS_FILE" -w "\n%{http_code}" -X POST \
              "https://models.github.ai/inference/chat/completions" \
              -H "Authorization: Bearer $GH_MODELS_TOKEN" \
              -H "Content-Type: application/json" \
              -d "$(jq -n \
                --arg system "$SYSTEM_PROMPT" \
                --arg diff "$CONTENT" \
                --arg model "$MODEL" \
                --argjson max_tokens "$MAX_REVIEW_TOKENS" \
                '{
                  model: $model,
                  messages: [
                    {role: "system", content: $system},
                    {role: "user", content: ("Review this pull request diff:\n\n" + $diff)}
                  ],
                  max_tokens: $max_tokens,
                  temperature: 0.2
                }')")

            HTTP_CODE=$(echo "$RESPONSE" | tail -1)
            BODY=$(echo "$RESPONSE" | sed '$d')
            RETRY_AFTER_HINT=$(echo "$BODY" | jq -r '.retry_after // empty' 2>/dev/null || true)
            if [ -n "$RETRY_AFTER_HINT" ]; then
              timeline "response purpose=$PURPOSE chunk=$CHUNK_ID model=$MODEL http=$HTTP_CODE retry_after=$RETRY_AFTER_HINT"
            else
              timeline "response purpose=$PURPOSE chunk=$CHUNK_ID model=$MODEL http=$HTTP_CODE"
            fi

            # Log rate-limit headers when present (free tier variability)
            if [ -f "$HEADERS_FILE" ]; then
              RATE_HEADERS=$(grep -iE 'x-ratelimit|retry-after' "$HEADERS_FILE" | tr -d '\r' || true)
              if [ -n "$RATE_HEADERS" ]; then
                while IFS= read -r HEADER_LINE; do
                  timeline "header purpose=$PURPOSE chunk=$CHUNK_ID model=$MODEL $HEADER_LINE"
                done <<< "$RATE_HEADERS"
              fi
            fi
          }

          review_with_chain() {
            local CONTENT="$1" PURPOSE="$2" CHUNK_ID="$3"
            local MODELS=()
            if [ -n "$REVIEW_LONG_CONTEXT_MODEL" ]; then
              MODELS+=("$REVIEW_LONG_CONTEXT_MODEL")
            fi
            MODELS+=("$REVIEW_MODEL" "$REVIEW_FALLBACK_MODEL")

            for MODEL in "${MODELS[@]}"; do
              timeline "trying_model purpose=$PURPOSE chunk=$CHUNK_ID model=$MODEL"
              ATTEMPT=0
              while [ "$ATTEMPT" -lt "$MAX_RETRY" ]; do
                ATTEMPT=$((ATTEMPT + 1))
                timeline "attempt purpose=$PURPOSE chunk=$CHUNK_ID model=$MODEL value=$ATTEMPT/$MAX_RETRY"
                call_model "$MODEL" "$CONTENT" "$PURPOSE" "$CHUNK_ID"

                if [ "$HTTP_CODE" = "200" ]; then
                  USED_MODEL="$MODEL"
                  echo "$BODY" | jq -r '.choices[0].message.content' > "review_$CHUNK_ID.md"
                  TOKENS=$(echo "$BODY" | jq '.usage.total_tokens // 0')
                  echo "$TOKENS" > "tokens_$CHUNK_ID.txt"
                  timeline "success purpose=$PURPOSE chunk=$CHUNK_ID model=$MODEL tokens=$TOKENS"
                  return 0
                fi

                if echo "$BODY" | jq -e '.error.code == "tokens_limit_reached"' >/dev/null 2>&1 || [ "$HTTP_CODE" = "413" ]; then
                  timeline "tokens_limit purpose=$PURPOSE chunk=$CHUNK_ID model=$MODEL http=$HTTP_CODE"
                  echo "::warning::Received tokens_limit_reached/413 from $MODEL; will fallback to chunking"
                  return 413
                fi

                timeline "attempt_failed purpose=$PURPOSE chunk=$CHUNK_ID model=$MODEL http=$HTTP_CODE"
                echo "::warning::Attempt $ATTEMPT failed (HTTP $HTTP_CODE) with $MODEL"
                if [ "$ATTEMPT" -lt "$MAX_RETRY" ]; then
                  RETRY_AFTER=$(echo "$BODY" | jq -r '.retry_after // empty' 2>/dev/null || true)
                  if [ -n "$RETRY_AFTER" ]; then
                    SLEEP="$RETRY_AFTER"
                  else
                    RAW_SLEEP=$((2 ** ATTEMPT))
                    SLEEP=$(( RAW_SLEEP < MAX_RETRY_SLEEP ? RAW_SLEEP : MAX_RETRY_SLEEP ))
                  fi
                  JITTER=$((RANDOM % 5))
                  SLEEP=$((SLEEP + JITTER))
                  timeline "backoff purpose=$PURPOSE chunk=$CHUNK_ID model=$MODEL sleep=${SLEEP}s"
                  echo "Retrying in ${SLEEP}s..."
                  sleep "$SLEEP"
                fi
              done
              timeline "model_exhausted purpose=$PURPOSE chunk=$CHUNK_ID model=$MODEL last_http=$HTTP_CODE"
              echo "::warning::All $MAX_RETRY attempts exhausted for $MODEL (HTTP $HTTP_CODE); trying next model..."
            done
            return 1
          }

          # 1) Try full diff if within soft limit
          if [ "$CHUNK_REQUIRED" -eq 0 ]; then
            DIFF_CONTENT=$(cat diff_full.txt)
            if review_with_chain "$DIFF_CONTENT" "full-diff" "full"; then
              echo "### Full diff review" > review.md
              cat review_full.md >> review.md
              echo >> review.md
              echo "tokens=$(cat tokens_full.txt)" >> "$GITHUB_OUTPUT"
              echo "model=$USED_MODEL" >> "$GITHUB_OUTPUT"
              echo "chunked=false" >> "$GITHUB_OUTPUT"
              timeline "full_diff_completed model=$USED_MODEL tokens=$(cat tokens_full.txt)"
              exit 0
            fi
            timeline "full_diff_fallback_to_chunking"
            echo "::warning::Full diff path failed or hit 413; switching to chunked review"
          else
            timeline "chunking_enabled_due_to_size full_diff_chars=${{ steps.diff.outputs.full_size }} max_review_chars=$MAX_REVIEW_CHARS"
            echo "Diff size exceeds MAX_REVIEW_CHARS; using chunked review"
          fi

          # 2) Chunked path (overlapping chunks for coherence)
          STEP=$((CHUNK_SIZE_CHARS - CHUNK_OVERLAP_CHARS))
          if [ "$STEP" -le 0 ]; then
            echo "::error::Invalid chunk config: CHUNK_SIZE_CHARS must be greater than CHUNK_OVERLAP_CHARS"
            exit 1
          fi

          DIFF_LEN=$(wc -c < diff_full.txt)
          timeline "chunking_config diff_len=$DIFF_LEN chunk_size=$CHUNK_SIZE_CHARS chunk_overlap=$CHUNK_OVERLAP_CHARS step=$STEP"
          CHUNK_COUNT=0
          OFFSET=0
          while [ "$OFFSET" -lt "$DIFF_LEN" ]; do
            CHUNK_COUNT=$((CHUNK_COUNT + 1))
            FILE=$(printf "diff_chunk_%02d.txt" "$CHUNK_COUNT")
            dd if=diff_full.txt of="$FILE" bs=1 skip="$OFFSET" count="$CHUNK_SIZE_CHARS" status=none
            timeline "chunk_created id=$(printf '%02d' "$CHUNK_COUNT") offset=$OFFSET"
            OFFSET=$((OFFSET + STEP))
          done

          if [ "$CHUNK_COUNT" -le 0 ]; then
            echo "::error::Chunking failed"
            exit 1
          fi

          timeline "chunking_started chunk_count=$CHUNK_COUNT"
          TOTAL_TOKENS=0
          > review.md
          for FILE in diff_chunk_*.txt; do
            CID=$(echo "$FILE" | sed 's/[^0-9]//g')
            CONTENT=$(cat "$FILE")
            if ! review_with_chain "$CONTENT" "chunk-$CID" "$CID"; then
              echo "::error::Chunk $CID failed"; exit 1
            fi
            echo "### Chunk $CID" >> review.md
            cat "review_${CID}.md" >> review.md
            echo >> review.md
            TOK=$(cat "tokens_${CID}.txt")
            TOTAL_TOKENS=$((TOTAL_TOKENS + TOK))
            timeline "chunk_completed id=$CID tokens=$TOK total_tokens=$TOTAL_TOKENS"
          done

          echo "tokens=$TOTAL_TOKENS" >> "$GITHUB_OUTPUT"
          echo "model=$USED_MODEL" >> "$GITHUB_OUTPUT"
          echo "chunked=true" >> "$GITHUB_OUTPUT"
          timeline "chunked_review_completed model=$USED_MODEL total_tokens=$TOTAL_TOKENS"

      - name: Append AI review timeline to workflow summary
        if: steps.diff.outputs.skip != 'true'
        run: |
          {
            echo "## AI Review Timeline"
            echo
            echo '```text'
            cat review_timeline.md
            echo '```'
          } >> "$GITHUB_STEP_SUMMARY"

      - name: Post review comment
        if: steps.diff.outputs.skip != 'true'
        uses: actions/github-script@v7
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const fs = require('fs');
            const review = fs.readFileSync('review.md', 'utf8');
            const truncated = '${{ steps.diff.outputs.truncated }}' === 'true';
            const truncatedAt = '${{ steps.diff.outputs.truncated_at }}';
            const tokens = '${{ steps.review.outputs.tokens }}';
            const model = '${{ steps.review.outputs.model }}';

            let footer = `\n\n---\n*ü§ñ AI Review ¬∑ ${model} ¬∑ ${tokens} tokens ¬∑ GitHub Models free tier ¬∑ 0 premium requests*`;
            if (truncated) {
              footer += `\n\n> ‚ö†Ô∏è **Diff truncated** to ${truncatedAt} chars (full diff: ${{ steps.diff.outputs.full_size }} chars). Changes beyond this point were **not reviewed**. Add label \`skip-ai-review\` to suppress, or split the PR.`;
            }

            await github.rest.issues.createComment({
              ...context.repo,
              issue_number: context.issue.number,
              body: `## üîç AI Code Review\n\n${review}${footer}`
            });

      - name: Skip notice
        if: steps.diff.outputs.skip == 'true'
        run: echo "::notice::No diff detected ‚Äî skipping AI review"

  pr-summary:
    name: AI PR Summary
    runs-on: ubuntu-latest
    if: ${{ !contains(github.event.pull_request.labels.*.name, 'skip-ai-review') }}
    env:
      SUMMARY_MODEL: "openai/gpt-4.1-mini"
      SUMMARY_FALLBACK_MODEL: "openai/gpt-4o-mini"
      SUMMARY_FALLBACK_MODEL_2: "meta/llama-3.3-70b-instruct"
      MAX_SUMMARY_CHARS: "12000"
      MAX_SUMMARY_TOKENS: "1000"
      MAX_RETRY: "5"
      MAX_RETRY_SLEEP: "60"
    steps:
      - name: Checkout
        uses: actions/checkout@v6
        with:
          fetch-depth: 0

      - name: Get PR info
        id: info
        run: |
          set -euo pipefail
          git diff ${{ github.event.pull_request.base.sha }}...${{ github.event.pull_request.head.sha }} > diff_full.txt
          head -c "$MAX_SUMMARY_CHARS" diff_full.txt > diff.txt
          git diff --name-status ${{ github.event.pull_request.base.sha }}...${{ github.event.pull_request.head.sha }} > files.txt

          if [ ! -s diff.txt ]; then
            echo "skip=true" >> "$GITHUB_OUTPUT"
          else
            echo "skip=false" >> "$GITHUB_OUTPUT"
          fi

      - name: Generate summary (with retry)
        if: steps.info.outputs.skip != 'true'
        id: summary
        env:
          GH_MODELS_TOKEN: ${{ secrets.MODELS_PAT }}
        run: |
          set -euo pipefail
          # Mask token to prevent accidental log exposure
          echo "::add-mask::$GH_MODELS_TOKEN"

          SYSTEM="Generate a concise PR summary in markdown. Include: ## Summary (1-2 sentences), ## Changes (list key changes), ## Impact (what's affected). Be concise."
          FILES=$(cat files.txt)
          DIFF=$(cat diff.txt)

          # Model fallback chain: primary ‚Üí fallback ‚Üí high-rate-limit fallback (#77)
          MODELS=("$SUMMARY_MODEL" "$SUMMARY_FALLBACK_MODEL" "$SUMMARY_FALLBACK_MODEL_2")
          HTTP_CODE=""
          BODY=""
          USED_MODEL=""

          for MODEL in "${MODELS[@]}"; do
            echo "Trying model: $MODEL"
            ATTEMPT=0
            while [ "$ATTEMPT" -lt "$MAX_RETRY" ]; do
              ATTEMPT=$((ATTEMPT + 1))
              echo "Attempt $ATTEMPT/$MAX_RETRY with $MODEL..."

              RESPONSE=$(curl -s -w "\n%{http_code}" -X POST \
                "https://models.github.ai/inference/chat/completions" \
                -H "Authorization: Bearer $GH_MODELS_TOKEN" \
                -H "Content-Type: application/json" \
                -d "$(jq -n \
                  --arg system "$SYSTEM" \
                  --arg files "$FILES" \
                  --arg diff "$DIFF" \
                  --arg model "$MODEL" \
                  --argjson max_tokens "$MAX_SUMMARY_TOKENS" \
                  '{
                    model: $model,
                    messages: [
                      {role: "system", content: $system},
                      {role: "user", content: ("Files changed:\n" + $files + "\n\nDiff:\n" + $diff)}
                    ],
                    max_tokens: $max_tokens,
                    temperature: 0.3
                  }')")

              HTTP_CODE=$(echo "$RESPONSE" | tail -1)
              BODY=$(echo "$RESPONSE" | sed '$d')

              if [ "$HTTP_CODE" = "200" ]; then
                USED_MODEL="$MODEL"
                break 2
              fi

              echo "::warning::Attempt $ATTEMPT failed (HTTP $HTTP_CODE) with $MODEL"
              if [ "$ATTEMPT" -lt "$MAX_RETRY" ]; then
                RETRY_AFTER=$(echo "$BODY" | jq -r '.retry_after // empty' 2>/dev/null || true)
                if [ -n "$RETRY_AFTER" ]; then
                  SLEEP="$RETRY_AFTER"
                else
                  RAW_SLEEP=$((2 ** ATTEMPT))
                  SLEEP=$(( RAW_SLEEP < MAX_RETRY_SLEEP ? RAW_SLEEP : MAX_RETRY_SLEEP ))
                fi
                JITTER=$((RANDOM % 5))
                SLEEP=$((SLEEP + JITTER))
                echo "Retrying in ${SLEEP}s..."
                sleep "$SLEEP"
              fi
            done

            if [ "$HTTP_CODE" != "200" ]; then
              echo "::warning::All $MAX_RETRY attempts exhausted for $MODEL (HTTP $HTTP_CODE); trying next model..."
            fi
          done

          if [ "$HTTP_CODE" != "200" ]; then
            echo "::error::All models failed after exhausting retries. Last HTTP $HTTP_CODE"
            echo "$BODY" | jq .error 2>/dev/null || true
            exit 1
          fi

          echo "$BODY" | jq -r '.choices[0].message.content' > summary.md
          echo "model=$USED_MODEL" >> "$GITHUB_OUTPUT"

      - name: Post summary
        if: steps.info.outputs.skip != 'true'
        uses: actions/github-script@v7
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const fs = require('fs');
            const summary = fs.readFileSync('summary.md', 'utf8');
            const model = '${{ steps.summary.outputs.model }}';
            await github.rest.issues.createComment({
              ...context.repo,
              issue_number: context.issue.number,
              body: `## üìù AI PR Summary\n\n${summary}\n\n---\n*ü§ñ Auto-generated ¬∑ ${model} ¬∑ GitHub Models free tier ¬∑ 0 premium requests*`
            });
